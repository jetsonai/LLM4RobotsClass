{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNdE9as156llJJZkFHcVpN7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FChlxcjT4ldq","executionInfo":{"status":"ok","timestamp":1728975400495,"user_tz":-540,"elapsed":21012,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}},"outputId":"12703015-f487-47ab-bdb6-259dacb075a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-15 06:56:19--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n","Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84125825 (80M) [application/x-gzip]\n","Saving to: ‘aclImdb_v1.tar.gz’\n","\n","aclImdb_v1.tar.gz   100%[===================>]  80.23M  28.3MB/s    in 2.8s    \n","\n","2024-10-15 06:56:22 (28.3 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n","\n"]}],"source":["!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","import os\n","\n","def load_data(path):\n","    texts = []\n","    labels = []\n","    for label_type in ['neg', 'pos']:\n","        dir_name = os.path.join(path, label_type)\n","        for fname in os.listdir(dir_name):\n","            if fname.endswith('.txt'):\n","                with open(os.path.join(dir_name, fname), 'r', encoding='utf-8') as f:\n","                    texts.append(f.read())\n","                labels.append(0 if label_type == 'neg' else 1)\n","    return texts, labels\n","\n","train_texts, train_labels = load_data('aclImdb/train')\n","test_texts, test_labels = load_data('aclImdb/test')"]},{"cell_type":"code","source":["import re\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","def preprocess(text):\n","    text = re.sub(r\"<.*>\", \"\", text)\n","    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n","    text = text.lower()\n","    tokens = word_tokenize(text)\n","    return tokens\n","\n","train_tokens = [preprocess(text) for text in train_texts]\n","test_tokens = [preprocess(text) for text in test_texts]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ha4scwdN5Ohj","executionInfo":{"status":"ok","timestamp":1728975438893,"user_tz":-540,"elapsed":38402,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}},"outputId":"2c74fd5f-75a7-4127-9b1e-205f4192ecee"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","all_tokens = [token for tokens in train_tokens for token in tokens]\n","word_counts = Counter(all_tokens)\n","vocab = ['<PAD>', '<UNK>'] + [word for word, count in word_counts.items() if count >= 5]\n","word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n","idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n","\n","vocab_size = len(vocab)\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJjl6pLN5sba","executionInfo":{"status":"ok","timestamp":1728975439248,"user_tz":-540,"elapsed":358,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}},"outputId":"b5faceb0-6121-4d27-9029-8f56b05d35d5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["21338\n"]}]},{"cell_type":"code","source":["max_seq_len = 200\n","\n","def tokens_to_indices(tokens_list, word_to_idx, max_seq_len):\n","    sequences = []\n","    for tokens in tokens_list:\n","        seq = [word_to_idx.get(token, word_to_idx['<UNK>']) for token in tokens]\n","        if len(seq) < max_seq_len:\n","            seq += [word_to_idx['<PAD>']] * (max_seq_len - len(seq))\n","        else:\n","            seq = seq[:max_seq_len]\n","        sequences.append(seq)\n","    return sequences\n","\n","train_sequences = tokens_to_indices(train_tokens, word_to_idx, max_seq_len)\n","test_sequences = tokens_to_indices(test_tokens, word_to_idx, max_seq_len)"],"metadata":{"id":"Fl3g3Swg6adX","executionInfo":{"status":"ok","timestamp":1728975440834,"user_tz":-540,"elapsed":1588,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class TextDataset(Dataset):\n","    def __init__(self, sequences, labels):\n","        super().__init__()\n","        self.sequences = sequences\n","        self.labels = labels\n","    def __len__(self):\n","        return len(self.sequences)\n","    def __getitem__(self, idx):\n","        sequence = torch.tensor(self.sequences[idx], dtype=torch.long)\n","        label = torch.tensor(self.labels[idx], dtype=torch.float)\n","        return sequence, label"],"metadata":{"id":"--3JgN_76yNe","executionInfo":{"status":"ok","timestamp":1728975445243,"user_tz":-540,"elapsed":4411,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_dataset = TextDataset(train_sequences, train_labels)\n","test_dataset = TextDataset(test_sequences, test_labels)\n","\n","batch_size = 64\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"WS8WTZYt7LbH","executionInfo":{"status":"ok","timestamp":1728975445244,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","class SentimentLSTM(nn.Module):\n","    def __init__(self, vocab_size, embed_size, hidden_size, output_size, num_layers):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        self.sigmoid = nn.Sigmoid()\n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        lstm_out, (hidden, cell) = self.lstm(embedded)\n","        out = self.fc(hidden[-1])\n","        out = self.sigmoid(out)\n","        return out.squeeze()"],"metadata":{"id":"0Zbz2_IA7Y_N","executionInfo":{"status":"ok","timestamp":1728975445244,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["embed_size=128\n","hidden_size=128\n","output_size=1\n","num_layers=2\n","num_epochs=5\n","learning_rate = 0.001\n","\n","model = SentimentLSTM(vocab_size, embed_size, hidden_size, output_size, num_layers)\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"jg_Yaox178UA","executionInfo":{"status":"ok","timestamp":1728975447974,"user_tz":-540,"elapsed":2734,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model.train()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    for sequences, labels in train_loader:\n","        sequences, labels = sequences.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QcADzLy8Or6","executionInfo":{"status":"ok","timestamp":1728975479371,"user_tz":-540,"elapsed":31400,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}},"outputId":"0e6d9a1f-5ecf-48e3-cd86-3dd16e30874a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5, Loss: 0.6933\n","Epoch 2/5, Loss: 0.6873\n","Epoch 3/5, Loss: 0.6522\n","Epoch 4/5, Loss: 0.6431\n","Epoch 5/5, Loss: 0.6722\n"]}]},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for sequences, labels in test_loader:\n","        sequences, labels = sequences.to(device), labels.to(device)\n","        outputs = model(sequences)\n","        predicted = (outputs > 0.5).float()\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print(f'테스트 정확도: {100 * correct / total:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1NnGWdoh8hep","executionInfo":{"status":"ok","timestamp":1728975559598,"user_tz":-540,"elapsed":2890,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}},"outputId":"1a8233d5-e09d-4120-950b-df11d74cdf00"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트 정확도: 53.10%\n"]}]},{"cell_type":"code","source":["def predict_sentiment(text):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    tokens = preprocess(text)\n","    seq = [word_to_idx.get(token, word_to_idx['<UNK>']) for token in tokens]\n","    if len(seq) < max_seq_len:\n","        seq += [word_to_idx['<PAD>']]*(max_seq_len - len(seq))\n","    else:\n","        seq = seq[:max_seq_len]\n","    sequence = torch.tensor(seq, dtype=torch.long).unsqueeze(0).to(device)\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(sequence)\n","        predicted = '긍정' if output.item() >= 0.5 else '부정'\n","        print(f'입력 문장: {text}')\n","        print(f'예측 확률: {output.item():.4f}')\n","        print(f'예측 결과: {predicted}')"],"metadata":{"id":"a-1R0aqF-U6q","executionInfo":{"status":"ok","timestamp":1728975826775,"user_tz":-540,"elapsed":335,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["test_sentence = \"This movie was fantastic! I really enjoyed it.\"\n","predict_sentiment(test_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ItKUy05_GZs","executionInfo":{"status":"ok","timestamp":1728975827102,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jinyeong Wang","userId":"15748183116968670585"}},"outputId":"f9191777-82bf-4e32-f3a7-5b6494e25def"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 문장: This movie was fantastic! I really enjoyed it.\n","예측 확률: 0.4828\n","예측 결과: 부정\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uAsBhmuX_KkQ"},"execution_count":null,"outputs":[]}]}