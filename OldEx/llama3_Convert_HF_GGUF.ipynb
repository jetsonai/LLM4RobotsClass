{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE22wdfI7zV_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "%cd /content/gdrive/MyDrive/LLMStudy/GGUF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKtX-dvG8PGu"
      },
      "source": [
        "### HF TO SNAPSHOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AmBZrK67wB3"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import snapshot_download\n",
        "# # 불러올 허깅페이스모델 (model_id 변수에 할당)\n",
        "model_id=\"rssaem/llama3_ko_8b_rs2\"\n",
        "# # 현재 폴더 기준 폴더 생성\n",
        "snapshot_download(repo_id=model_id, local_dir=\"llama3_rscode\",\n",
        "                           local_dir_use_symlinks=False, revision=\"main\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IScVtsf0B0pQ"
      },
      "outputs": [],
      "source": [
        "# Setup Llama.cpp and install required packages\n",
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "!cd llama.cpp && LLAMA_CUBLAS=1 make"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r llama.cpp/requirements.txt"
      ],
      "metadata": {
        "id": "Xu7N-pINV3Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3yjU5UUCl1v"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD0vqLCyCJWo"
      },
      "outputs": [],
      "source": [
        "!python llama.cpp/convert-hf-to-gguf.py llama3_rscode --outfile llama3-rscode-8b.gguf --outtype f16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDByBv2-H4Kj"
      },
      "outputs": [],
      "source": [
        "import  huggingface_hub\n",
        "huggingface_hub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_mu3nVeHUq3"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "# gguf 파일 경로\n",
        "file_path = \"llama3-rs-8b.gguf\"\n",
        "\n",
        "# Hugging Face 저장소 이름\n",
        "repo_name = \"rsaem/llama3-ko-8b-rs-gguf2\"\n",
        "\n",
        "# 파일 업로드\n",
        "api.upload_file(\n",
        "    path_or_fileobj=file_path,\n",
        "    path_in_repo=\"llama3-rscode-8b.gguf\",  # 저장소 내 파일 경로\n",
        "    repo_id=repo_name,\n",
        "    repo_type=\"model\",  # 모델 저장소에 업로드\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQjP5FMSHUlf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W_cDpmCB7No"
      },
      "outputs": [],
      "source": [
        "!python llama.cpp/convert-hf-to-gguf.py phi2 --outfile \"phi2/phi2-v2-fp16.bin\" --outtype f16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbIha-w98S_z"
      },
      "outputs": [],
      "source": [
        "# llama-cpp-python 라이브러리가 GPU 가속을 위해 cuBLAS 라이브러리를 사용하도록 설정\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbmPctP0-Tli"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDJFxE7B-XN2"
      },
      "outputs": [],
      "source": [
        "model_name = \"rssaem/llama3-ko-8b-rs-gguf2\"\n",
        "model_file = \"llama3-rscode-8b.gguf\"\n",
        "model_path = hf_hub_download(model_name,\n",
        "                             filename=model_file,\n",
        "                             local_dir=\"llama3_hkcode_gguf\")\n",
        "print(\"My model path: \", model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mpj0RHc-2e3"
      },
      "outputs": [],
      "source": [
        "llm = Llama(model_path=model_path,\n",
        "            n_gpu_layers=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5yMAB1i-5zS"
      },
      "outputs": [],
      "source": [
        "response = llm(\"스마트금융과는 어디에 위치하나요?\", max_tokens=200)\n",
        "response"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}